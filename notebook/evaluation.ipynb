{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb06eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d710ba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08439155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# QA\n",
    "inputs = [\n",
    "    \"For customer-facing applications, which company's models dominate the top rankings?\",\n",
    "    \"What percentage of respondents are using RAG in some form?\",\n",
    "    \"How often are most respondents updating their models?\",\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\",\n",
    "    \"70% of respondents are using RAG in some form.\",\n",
    "    \"More than 50% update their models at least monthly, with 17% doing so weekly.\",\n",
    "]\n",
    "\n",
    "# Dataset\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Write to csv\n",
    "csv_path = \"data/qa_dataset.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8ee46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['8a7ff678-83f3-470c-9cd5-e58e2dde943e',\n",
       "  '57bb0360-1d48-425c-a00e-53966a7d4e1d',\n",
       "  'f7f9b516-f9ee-4241-a9b0-1c4391ec04d3'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "client = Client()\n",
    "dataset = client.create_dataset(dataset_name=\"RAG Report QA Dataset\", description=\"Input & expected output pairs from RAG report\")\n",
    "\n",
    "\n",
    "client.create_examples(dataset_id=dataset.id, inputs=[{\"question\": q} for q in inputs], outputs=[{\"answer\": a} for a in outputs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee4958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(\"/Users/debdoot/Desktop/LLMOPS_RAG\")\n",
    "\n",
    "from multi_doc_chat.src.ingestion import DocumentIngestionPipeline\n",
    "from multi_doc_chat.src.retriever import DocumentRetriever\n",
    "import uuid\n",
    "\n",
    "\n",
    "def answer_ai_report_question(\n",
    "    inputs: dict,\n",
    "    data_path: str = \"/Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    k: int = 5,\n",
    "    session_id: str = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Answer questions about the AI Engineering Report using RAG.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary containing the question, e.g., {\"question\": \"What is RAG?\"}\n",
    "        data_path: Path to the AI Engineering Report text file\n",
    "        chunk_size: Size of text chunks for splitting\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        k: Number of documents to retrieve\n",
    "        session_id: Optional session ID for vector store isolation\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the answer, e.g., {\"answer\": \"RAG stands for...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract question from inputs\n",
    "        question = inputs.get(\"question\", \"\")\n",
    "        if not question:\n",
    "            return {\"answer\": \"No question provided\"}\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not Path(data_path).exists():\n",
    "            return {\"answer\": f\"Data file not found: {data_path}\"}\n",
    "        \n",
    "        # Generate or use provided session ID\n",
    "        if session_id is None:\n",
    "            session_id = str(uuid.uuid4())[:12]\n",
    "        \n",
    "        # Define vector store path\n",
    "        vector_store_base = os.path.join(os.path.dirname(data_path), \"vector_store\")\n",
    "        session_vector_store = os.path.join(vector_store_base, f\"session_{session_id}\")\n",
    "        \n",
    "        # Check if vector store already exists for this session\n",
    "        if not os.path.exists(session_vector_store):\n",
    "            # Build vector store using DocumentIngestionPipeline\n",
    "            ingestor = DocumentIngestionPipeline(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap,\n",
    "                vector_store_path=vector_store_base,\n",
    "                session_id=session_id\n",
    "            )\n",
    "            \n",
    "            # Process the document\n",
    "            ingestor.process_documents(\n",
    "                file_paths=[data_path],\n",
    "                metadata={\"source\": \"AI_Engineering_Report\", \"type\": \"evaluation\"}\n",
    "            )\n",
    "        \n",
    "        # Create retriever\n",
    "        retriever = DocumentRetriever(\n",
    "            vector_store_path=vector_store_base,\n",
    "            session_id=session_id,\n",
    "            top_k=k,\n",
    "            score_threshold=0.3\n",
    "        )\n",
    "        \n",
    "        # Query documents using standard RAG\n",
    "        answer, docs = retriever.query_documents(\n",
    "            query=question,\n",
    "            prompt_type=\"standard\",\n",
    "            chat_history=[]\n",
    "        )\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c385c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:03:07,926 - multi_doc_chat.src.ingestion - INFO - Initialized document ingestion pipeline with chunk_size=1000, chunk_overlap=200, session_id=9c91b37c-ab2\n",
      "2025-10-10 17:03:07,926 - multi_doc_chat.src.ingestion - INFO - Starting document ingestion for 1 files with session_id=9c91b37c-ab2\n",
      "2025-10-10 17:03:07,927 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:03:07,927 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:03:07,927 - multi_doc_chat.src.ingestion - INFO - Loaded 1 documents successfully\n",
      "2025-10-10 17:03:07,927 - multi_doc_chat.src.ingestion - INFO - Split documents into 1 chunks\n",
      "2025-10-10 17:03:07,928 - multi_doc_chat.src.ingestion - INFO - Average chunk length: 721.00 characters\n",
      "2025-10-10 17:03:13,298 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:03:13,304 - faiss.loader - INFO - Loading faiss.\n",
      "2025-10-10 17:03:13,344 - faiss.loader - INFO - Successfully loaded faiss.\n",
      "2025-10-10 17:03:13,347 - multi_doc_chat.src.ingestion - INFO - Created vector store with 1 embedded chunks\n",
      "2025-10-10 17:03:13,348 - multi_doc_chat.src.ingestion - INFO - Saved vector store to /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_9c91b37c-ab2\n",
      "2025-10-10 17:03:13,374 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_9c91b37c-ab2\n",
      "2025-10-10 17:03:13,374 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_9c91b37c-ab2\n",
      "2025-10-10 17:03:13,398 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:03:13,398 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:03:13,399 - retriever.py - INFO - Initialized document retriever with session_id=9c91b37c-ab2, top_k=5\n",
      "2025-10-10 17:03:13,399 - retriever.py - INFO - Initialized document retriever with session_id=9c91b37c-ab2, top_k=5\n",
      "2025-10-10 17:03:15,247 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:03:15,255 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:03:15,255 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:03:17,059 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: For customer-facing applications, which company's models dominate the top rankings?\n",
      "\n",
      "Answer: For customer-facing applications, OpenAI's models dominate the top rankings, with 3 out of the top 5 and half of the top 10 most popular models being from OpenAI (Document 1).\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a sample question\n",
    "test_input = {\"question\": \"For customer-facing applications, which company's models dominate the top rankings?\"}\n",
    "result = answer_ai_report_question(test_input)\n",
    "print(\"Question:\", test_input[\"question\"])\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb99a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:05:52,857 - multi_doc_chat.src.ingestion - INFO - Initialized document ingestion pipeline with chunk_size=1000, chunk_overlap=200, session_id=45f37fcf-296\n",
      "2025-10-10 17:05:52,857 - multi_doc_chat.src.ingestion - INFO - Starting document ingestion for 1 files with session_id=45f37fcf-296\n",
      "2025-10-10 17:05:52,858 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:52,858 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:52,858 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:52,860 - multi_doc_chat.src.ingestion - INFO - Loaded 1 documents successfully\n",
      "2025-10-10 17:05:52,861 - multi_doc_chat.src.ingestion - INFO - Split documents into 1 chunks\n",
      "2025-10-10 17:05:52,861 - multi_doc_chat.src.ingestion - INFO - Average chunk length: 721.00 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all questions from the dataset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:05:54,793 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:05:54,796 - multi_doc_chat.src.ingestion - INFO - Created vector store with 1 embedded chunks\n",
      "2025-10-10 17:05:54,799 - multi_doc_chat.src.ingestion - INFO - Saved vector store to /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_45f37fcf-296\n",
      "2025-10-10 17:05:54,842 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_45f37fcf-296\n",
      "2025-10-10 17:05:54,842 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_45f37fcf-296\n",
      "2025-10-10 17:05:54,869 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:05:54,869 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:05:54,870 - retriever.py - INFO - Initialized document retriever with session_id=45f37fcf-296, top_k=5\n",
      "2025-10-10 17:05:54,870 - retriever.py - INFO - Initialized document retriever with session_id=45f37fcf-296, top_k=5\n",
      "2025-10-10 17:05:56,020 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:05:56,022 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:05:56,022 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:05:57,612 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:05:57,658 - multi_doc_chat.src.ingestion - INFO - Initialized document ingestion pipeline with chunk_size=1000, chunk_overlap=200, session_id=fe2f0147-2b3\n",
      "2025-10-10 17:05:57,658 - multi_doc_chat.src.ingestion - INFO - Starting document ingestion for 1 files with session_id=fe2f0147-2b3\n",
      "2025-10-10 17:05:57,659 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:57,659 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:57,659 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:57,659 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:05:57,660 - multi_doc_chat.src.ingestion - INFO - Loaded 1 documents successfully\n",
      "2025-10-10 17:05:57,660 - multi_doc_chat.src.ingestion - INFO - Split documents into 1 chunks\n",
      "2025-10-10 17:05:57,660 - multi_doc_chat.src.ingestion - INFO - Average chunk length: 721.00 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: For customer-facing applications, which company's models dominate the top rankings?\n",
      "A1: For customer-facing applications, OpenAI's models dominate the top rankings, with 3 out of the top 5 and half of the top 10 most popular models being from OpenAI (Document 1).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:05:58,724 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:05:58,728 - multi_doc_chat.src.ingestion - INFO - Created vector store with 1 embedded chunks\n",
      "2025-10-10 17:05:58,730 - multi_doc_chat.src.ingestion - INFO - Saved vector store to /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_fe2f0147-2b3\n",
      "2025-10-10 17:05:58,777 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_fe2f0147-2b3\n",
      "2025-10-10 17:05:58,777 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_fe2f0147-2b3\n",
      "2025-10-10 17:05:58,805 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:05:58,805 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:05:58,806 - retriever.py - INFO - Initialized document retriever with session_id=fe2f0147-2b3, top_k=5\n",
      "2025-10-10 17:05:58,806 - retriever.py - INFO - Initialized document retriever with session_id=fe2f0147-2b3, top_k=5\n",
      "2025-10-10 17:06:00,286 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:06:00,289 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:06:00,289 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:06:01,748 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:06:01,801 - multi_doc_chat.src.ingestion - INFO - Initialized document ingestion pipeline with chunk_size=1000, chunk_overlap=200, session_id=6d1c5e64-89e\n",
      "2025-10-10 17:06:01,802 - multi_doc_chat.src.ingestion - INFO - Starting document ingestion for 1 files with session_id=6d1c5e64-89e\n",
      "2025-10-10 17:06:01,803 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:06:01,803 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:06:01,803 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:06:01,803 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:06:01,803 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:06:01,805 - multi_doc_chat.src.ingestion - INFO - Loaded 1 documents successfully\n",
      "2025-10-10 17:06:01,806 - multi_doc_chat.src.ingestion - INFO - Split documents into 1 chunks\n",
      "2025-10-10 17:06:01,806 - multi_doc_chat.src.ingestion - INFO - Average chunk length: 721.00 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: What percentage of respondents are using RAG in some form?\n",
      "A2: 70% of respondents are using RAG (Retrieval-Augmented Generation) in some form (Document 1).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:06:02,938 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:06:02,941 - multi_doc_chat.src.ingestion - INFO - Created vector store with 1 embedded chunks\n",
      "2025-10-10 17:06:02,943 - multi_doc_chat.src.ingestion - INFO - Saved vector store to /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_6d1c5e64-89e\n",
      "2025-10-10 17:06:02,985 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_6d1c5e64-89e\n",
      "2025-10-10 17:06:02,985 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_6d1c5e64-89e\n",
      "2025-10-10 17:06:03,013 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:06:03,013 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:06:03,013 - retriever.py - INFO - Initialized document retriever with session_id=6d1c5e64-89e, top_k=5\n",
      "2025-10-10 17:06:03,013 - retriever.py - INFO - Initialized document retriever with session_id=6d1c5e64-89e, top_k=5\n",
      "2025-10-10 17:06:04,361 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:06:04,363 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:06:04,363 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:06:05,957 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: How often are most respondents updating their models?\n",
      "A3: Most respondents are updating their models at least monthly, with more than 50% indicating this frequency of updates (Document 1).\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing all questions from the dataset:\\n\")\n",
    "for i, q in enumerate(inputs, 1):\n",
    "    test_input = {\"question\": q}\n",
    "    result = answer_ai_report_question(test_input)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\"A{i}: {result['answer']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95505573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using evaluation session ID: a4319021-65d\n",
      "View the evaluation results for experiment: 'rag-faiss-ai-report-ad7370e2' at:\n",
      "https://smith.langchain.com/o/f4193c4f-4476-4810-9690-8c19b2be5138/datasets/16dd0f1e-f329-46ba-8457-27711255827b/compare?selectedSessions=62e9c221-9a0b-4036-8acd-4cc26ae1bf11\n",
      "\n",
      "\n",
      "View the evaluation results for experiment: 'rag-faiss-ai-report-ad7370e2' at:\n",
      "https://smith.langchain.com/o/f4193c4f-4476-4810-9690-8c19b2be5138/datasets/16dd0f1e-f329-46ba-8457-27711255827b/compare?selectedSessions=62e9c221-9a0b-4036-8acd-4cc26ae1bf11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2025-10-10 17:16:43,379 - multi_doc_chat.src.ingestion - INFO - Initialized document ingestion pipeline with chunk_size=1000, chunk_overlap=200, session_id=a4319021-65d\n",
      "2025-10-10 17:16:43,379 - multi_doc_chat.src.ingestion - INFO - Starting document ingestion for 1 files with session_id=a4319021-65d\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,382 - multi_doc_chat.src.ingestion - INFO - Loaded 1 documents successfully\n",
      "2025-10-10 17:16:43,382 - multi_doc_chat.src.ingestion - INFO - Split documents into 1 chunks\n",
      "2025-10-10 17:16:43,383 - multi_doc_chat.src.ingestion - INFO - Average chunk length: 721.00 characters\n",
      "2025-10-10 17:16:43,379 - multi_doc_chat.src.ingestion - INFO - Initialized document ingestion pipeline with chunk_size=1000, chunk_overlap=200, session_id=a4319021-65d\n",
      "2025-10-10 17:16:43,379 - multi_doc_chat.src.ingestion - INFO - Starting document ingestion for 1 files with session_id=a4319021-65d\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,381 - loaders.py - INFO - Loaded 1 documents from /Users/debdoot/Desktop/LLMOPS_RAG/data/ai_report.txt\n",
      "2025-10-10 17:16:43,382 - multi_doc_chat.src.ingestion - INFO - Loaded 1 documents successfully\n",
      "2025-10-10 17:16:43,382 - multi_doc_chat.src.ingestion - INFO - Split documents into 1 chunks\n",
      "2025-10-10 17:16:43,383 - multi_doc_chat.src.ingestion - INFO - Average chunk length: 721.00 characters\n",
      "2025-10-10 17:16:44,767 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:44,769 - multi_doc_chat.src.ingestion - INFO - Created vector store with 1 embedded chunks\n",
      "2025-10-10 17:16:44,773 - multi_doc_chat.src.ingestion - INFO - Saved vector store to /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:44,767 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:44,769 - multi_doc_chat.src.ingestion - INFO - Created vector store with 1 embedded chunks\n",
      "2025-10-10 17:16:44,773 - multi_doc_chat.src.ingestion - INFO - Saved vector store to /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:44,811 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:44,811 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:44,811 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:44,811 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:44,837 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:44,837 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:44,838 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:44,838 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:44,837 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:44,837 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:44,838 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:44,838 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:46,188 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:46,191 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:46,191 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:46,188 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:46,191 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:46,191 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:47,745 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:47,745 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:49,979 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "1it [00:06,  6.64s/it]2025-10-10 17:16:49,979 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "1it [00:06,  6.64s/it]2025-10-10 17:16:50,034 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:50,034 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:50,034 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:50,034 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:50,062 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:51,256 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:51,260 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:51,260 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:51,256 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:51,260 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:51,260 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:52,761 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:52,761 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:55,403 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2it [00:12,  5.92s/it]2025-10-10 17:16:55,403 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2it [00:12,  5.92s/it]2025-10-10 17:16:55,456 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:55,456 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:55,456 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:55,456 - retriever.py - INFO - Loaded vector store from /Users/debdoot/Desktop/LLMOPS_RAG/data/vector_store/session_a4319021-65d\n",
      "2025-10-10 17:16:55,483 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:55,483 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:55,484 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:55,484 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:55,483 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:55,483 - retriever.py - INFO - Initialized LLM with model gpt-4o-mini\n",
      "2025-10-10 17:16:55,484 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:55,484 - retriever.py - INFO - Initialized document retriever with session_id=a4319021-65d, top_k=5\n",
      "2025-10-10 17:16:56,608 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:56,611 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:56,611 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:56,608 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:56,611 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:56,611 - retriever.py - INFO - Retrieved 1 relevant documents for query\n",
      "2025-10-10 17:16:58,166 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:16:58,166 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:17:00,419 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "3it [00:17,  5.51s/it]2025-10-10 17:17:00,419 - httpx - INFO - HTTP Request: POST https://dept-podcast-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n",
      "3it [00:18,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation complete! Results: <ExperimentResults rag-faiss-ai-report-ad7370e2>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "\n",
    "evaluation_session_id = str(uuid.uuid4())[:12]\n",
    "print(f\"Using evaluation session ID: {evaluation_session_id}\")\n",
    "\n",
    "# Configure Azure OpenAI for the evaluator\n",
    "azure_llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"API_VERSION\"),\n",
    "    deployment_name=os.getenv(\"OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "\n",
    "qa_evaluator = [\n",
    "    LangChainStringEvaluator(\n",
    "        \"cot_qa\",\n",
    "        config={\"llm\": azure_llm} \n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "dataset_name = \"RAG Report QA Dataset\"  \n",
    "\n",
    "\n",
    "def answer_with_session(inputs: dict) -> dict:\n",
    "    \"\"\"Wrapper to use consistent session_id across all evaluations.\"\"\"\n",
    "    return answer_ai_report_question(\n",
    "        inputs=inputs,\n",
    "        session_id=evaluation_session_id,\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        k=5\n",
    "    )\n",
    "\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    answer_with_session,\n",
    "    data=dataset_name,\n",
    "    evaluators=qa_evaluator,\n",
    "    experiment_prefix=\"rag-faiss-ai-report\",\n",
    "    # Experiment metadata\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "        \"session_id\": evaluation_session_id,\n",
    "        \"score_threshold\": 0.3,\n",
    "        \"evaluator_model\": os.getenv(\"OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"\\nEvaluation complete! Results: {experiment_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18d299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
